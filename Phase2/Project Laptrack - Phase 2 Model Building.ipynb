{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38b0f7c-bde3-44a6-9bd3-8d773744da46",
   "metadata": {},
   "source": [
    "# 1. Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "531360f3-1931-4f74-bf46-30bb29b31805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78cb09-7909-41a0-8b68-c7fb21f192a9",
   "metadata": {},
   "source": [
    "# 2. Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c256b268-9ca4-40f7-abef-574fc1b243bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Laptop_Model_Name</th>\n",
       "      <th>Laptop_Model_Number</th>\n",
       "      <th>Processor_Brand</th>\n",
       "      <th>Processor_Model</th>\n",
       "      <th>Storage_Type</th>\n",
       "      <th>Operating_System</th>\n",
       "      <th>Display_Resolution</th>\n",
       "      <th>Extracted_Rating</th>\n",
       "      <th>Battery_Life(Hours_Upto)</th>\n",
       "      <th>...</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Time_Of_Extraction</th>\n",
       "      <th>URL</th>\n",
       "      <th>Source</th>\n",
       "      <th>Storage_Capacity(GB)</th>\n",
       "      <th>Display_Size(Inches)</th>\n",
       "      <th>RAM(GB)</th>\n",
       "      <th>No_Of_Reviews</th>\n",
       "      <th>Laptop_Dimensions</th>\n",
       "      <th>Laptop_Weight(Pounds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell</td>\n",
       "      <td>Latitude 3540 Laptop</td>\n",
       "      <td>None</td>\n",
       "      <td>Intel</td>\n",
       "      <td>1355U</td>\n",
       "      <td>SSD</td>\n",
       "      <td>Windows 11 Professional</td>\n",
       "      <td>1920x1080 MP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-04 18:23:39</td>\n",
       "      <td>https://www.amazon.com/sspa/click?ie=UTF8&amp;spc=...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>4000</td>\n",
       "      <td>15.6</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.71 x 14.13 x 9.44 inches</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP</td>\n",
       "      <td>17t-cn3004</td>\n",
       "      <td>17t-cn3004208</td>\n",
       "      <td>Intel</td>\n",
       "      <td>Intel Core i5</td>\n",
       "      <td>SSD</td>\n",
       "      <td>Windows 11 Pro</td>\n",
       "      <td>1600x900 Pixels</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-04 18:23:42</td>\n",
       "      <td>https://www.amazon.com/sspa/click?ie=UTF8&amp;spc=...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>4096</td>\n",
       "      <td>17.3</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81 x 10.15 x 15.78 inches</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell</td>\n",
       "      <td>Dell Inspiron 15.6\" Touchscreen Laptop</td>\n",
       "      <td>None</td>\n",
       "      <td>Intel</td>\n",
       "      <td>1355U</td>\n",
       "      <td>SSD</td>\n",
       "      <td>Windows 11 Pro</td>\n",
       "      <td>1920x1080 Pixels</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-04 18:23:45</td>\n",
       "      <td>https://www.amazon.com/sspa/click?ie=UTF8&amp;spc=...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>4096</td>\n",
       "      <td>15.6</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>9.25 x 0.75 x 14.11 inches</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Pro</td>\n",
       "      <td>Mvvm2ll/a</td>\n",
       "      <td>Intel</td>\n",
       "      <td>Core i9</td>\n",
       "      <td>SSD</td>\n",
       "      <td>Mac OS X 10.0 Cheetah</td>\n",
       "      <td>2560 x 1600 Pixels</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-04 18:23:54</td>\n",
       "      <td>https://www.amazon.com/2019-Apple-MacBook-16-i...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2048</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16</td>\n",
       "      <td>109</td>\n",
       "      <td>15.63 x 2.40 x 11.14 inches</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP</td>\n",
       "      <td>TPN-Q279</td>\n",
       "      <td>TPN-Q279</td>\n",
       "      <td>AMD</td>\n",
       "      <td>Ryzen 5</td>\n",
       "      <td>SSD</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>1920 x 1080 Pixels</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-04 18:23:57</td>\n",
       "      <td>https://www.amazon.com/HP-i7-1355U-i5-14400F-G...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2048</td>\n",
       "      <td>15.6</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.93 x 10.04 x 14.09 inches</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand                       Laptop_Model_Name Laptop_Model_Number  \\\n",
       "0   Dell                    Latitude 3540 Laptop                None   \n",
       "1     HP                              17t-cn3004       17t-cn3004208   \n",
       "2   Dell  Dell Inspiron 15.6\" Touchscreen Laptop                None   \n",
       "3  Apple                             MacBook Pro           Mvvm2ll/a   \n",
       "4     HP                                TPN-Q279            TPN-Q279   \n",
       "\n",
       "  Processor_Brand Processor_Model Storage_Type         Operating_System  \\\n",
       "0           Intel           1355U          SSD  Windows 11 Professional   \n",
       "1           Intel   Intel Core i5          SSD           Windows 11 Pro   \n",
       "2           Intel           1355U          SSD           Windows 11 Pro   \n",
       "3           Intel         Core i9          SSD    Mac OS X 10.0 Cheetah   \n",
       "4             AMD         Ryzen 5          SSD          Windows 11 Home   \n",
       "\n",
       "   Display_Resolution  Extracted_Rating  Battery_Life(Hours_Upto)  ...  Stock  \\\n",
       "0        1920x1080 MP               NaN                       NaN  ...      1   \n",
       "1     1600x900 Pixels               5.0                       NaN  ...      1   \n",
       "2    1920x1080 Pixels               NaN                       NaN  ...      1   \n",
       "3  2560 x 1600 Pixels               4.0                      11.0  ...      1   \n",
       "4  1920 x 1080 Pixels               3.8                       NaN  ...      1   \n",
       "\n",
       "    Time_Of_Extraction                                                URL  \\\n",
       "0  2024-11-04 18:23:39  https://www.amazon.com/sspa/click?ie=UTF8&spc=...   \n",
       "1  2024-11-04 18:23:42  https://www.amazon.com/sspa/click?ie=UTF8&spc=...   \n",
       "2  2024-11-04 18:23:45  https://www.amazon.com/sspa/click?ie=UTF8&spc=...   \n",
       "3  2024-11-04 18:23:54  https://www.amazon.com/2019-Apple-MacBook-16-i...   \n",
       "4  2024-11-04 18:23:57  https://www.amazon.com/HP-i7-1355U-i5-14400F-G...   \n",
       "\n",
       "   Source Storage_Capacity(GB)  Display_Size(Inches)  RAM(GB)  No_Of_Reviews  \\\n",
       "0  Amazon                 4000                  15.6       64              0   \n",
       "1  Amazon                 4096                  17.3       64              1   \n",
       "2  Amazon                 4096                  15.6       32              0   \n",
       "3  Amazon                 2048                  16.0       16            109   \n",
       "4  Amazon                 2048                  15.6       16              7   \n",
       "\n",
       "             Laptop_Dimensions Laptop_Weight(Pounds)  \n",
       "0   0.71 x 14.13 x 9.44 inches                  4.00  \n",
       "1  0.81 x 10.15 x 15.78 inches                  5.00  \n",
       "2   9.25 x 0.75 x 14.11 inches                  3.60  \n",
       "3  15.63 x 2.40 x 11.14 inches                  5.68  \n",
       "4  0.93 x 10.04 x 14.09 inches                  7.39  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = sqlite3.connect(r'../database/laptrack.db')\n",
    "\n",
    "laptop_df = pd.read_sql_query(\"SELECT * FROM Laptop_Phase_2\", cursor)\n",
    "\n",
    "cursor.close()\n",
    "\n",
    "laptop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0b5ebfb6-4e3b-4164-ad58-5ef094821073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4236, 21)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d56a5c5-8c91-4f72-9ebe-0a641a455074",
   "metadata": {},
   "source": [
    "# 3. Preparing the dataset for Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "de632c30-15c6-46fb-bcdd-7ead6fb35a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns for each type\n",
    "categorical_cols = ['Brand', 'Processor_Brand', 'Operating_System', 'Storage_Type', 'Processor_Model']\n",
    "numerical_cols = ['Extracted_Rating', 'Storage_Capacity(GB)', 'Display_Size(Inches)', 'RAM(GB)', 'No_Of_Reviews', 'Laptop_Weight(Pounds)', 'Price']\n",
    "\n",
    "decidingColumns = categorical_cols + numerical_cols\n",
    "decidingColumns.append('Stock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2009167d-8613-47c2-96fe-41604cd1e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', numerical_imputer), \n",
    "            ('scaler', StandardScaler()) \n",
    "        ]), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a3c7134a-dc40-4b1f-a3e5-a58bc85ed6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [ 1.93261664e+03  8.76801540e+02  8.63892153e+02  8.01952916e+02\n",
      "  8.93311211e+02  5.67484275e+02  5.07308127e+02  6.07983841e+02\n",
      "  1.10533054e+03  4.46228376e+02  4.29368430e+02  4.74647485e+02\n",
      "  2.87857465e+02  7.27963724e+02  1.07826641e+03  4.41165067e+02\n",
      "  4.00015273e+02  2.34002830e+02  1.19530728e+03  8.41912411e+02\n",
      "  4.89819079e+02  1.86727046e+03  5.54635809e+02  4.86479759e+02\n",
      "  3.39263058e+02  6.73199200e+02  3.68243682e+02  8.92268097e+02\n",
      "  6.40807896e+02  2.13964378e+03  3.27627699e+02  8.69036273e+02\n",
      "  4.10292679e+02  1.05679739e+03  1.92216529e+03  4.89471253e+02\n",
      "  6.78508539e+02  3.98028691e+02  2.52389064e+02  3.85374587e+02\n",
      "  1.32050340e+03  8.70872108e+02  1.12969832e+03  5.83577309e+02\n",
      "  7.56985084e+02  4.41938151e+02  6.91988340e+02  4.58457299e+02\n",
      "  1.29495875e+03  4.70061496e+02  4.45944528e+02  5.28891637e+02\n",
      "  3.73049391e+02  3.82553687e+02  4.13441409e+02  4.43807101e+02\n",
      "  2.03505449e+03  5.94440784e+02  3.36428563e+03  1.27153332e+03\n",
      "  7.16864981e+02  1.32585466e+03  7.27196467e+02  7.68957326e+02\n",
      "  9.72368358e+02  1.14919007e+02  2.69283616e+03  9.54000352e+02\n",
      "  9.46292248e+02  1.60142086e+03  4.65298660e+02  1.24427301e+03\n",
      "  9.24358883e+02  2.74417576e+02  1.40095783e+03  5.16563756e+02\n",
      "  1.21095284e+03  2.08223892e+02  9.63786555e+02  6.42936321e+02\n",
      "  1.17383991e+03  3.90753588e+02  1.10770360e+03  8.18322846e+02\n",
      "  1.76528212e+03  4.41065560e+02  9.53072777e+02  2.05307454e+03\n",
      "  2.37523872e+03  1.15591805e+03  6.08570063e+02  8.13703390e+02\n",
      "  9.33354678e+02  1.09280466e+02  5.09503680e+02  8.42162926e+02\n",
      "  5.76298822e+02  1.80712774e+03  6.04960844e+02  6.65900734e+02\n",
      "  5.79093345e+02  5.46498099e+02  4.47615496e+02  1.09756708e+03\n",
      "  6.86214768e+02  4.12975180e+02  1.15619843e+03  9.22018431e+02\n",
      "  9.40253033e+02  7.92518824e+02  1.94933866e+03  1.91408458e+03\n",
      "  5.07084596e+02  1.54078077e+03  7.93575898e+02  5.56001456e+02\n",
      "  8.75278052e+02  8.76188804e+02  1.23160393e+03  5.54635809e+02\n",
      "  1.10942809e+03  7.24380174e+02  9.86791394e+02  9.94961667e+02\n",
      "  8.15132344e+02  9.92127670e+02  7.86297596e+02  9.46292248e+02\n",
      "  5.83046059e+02  8.57337833e+02  2.21447002e+03  4.50732891e+02\n",
      "  5.77141436e+02  1.58497512e+03  5.61558448e+02  1.38500599e+03\n",
      "  8.96243343e+02  6.06457789e+02 -8.51379319e+01  7.08865556e+02\n",
      "  1.01529070e+03  2.74417576e+02  9.04038325e+02  1.27418062e+03\n",
      "  5.05293932e+02  2.73437597e+02  2.79138493e+02  8.84021129e+02\n",
      "  1.20383260e+03  5.37419248e+02  4.77361288e+02  5.73631313e+02\n",
      "  4.59281391e+02  6.92541524e+02  4.55593922e+02  8.25275911e+02\n",
      "  4.97468749e+02  3.75878229e+02  2.41808657e+03  1.28263033e+03\n",
      "  9.10580639e+02  1.29163312e+03  1.38478897e+03  1.23475252e+03\n",
      "  4.65286913e+02  1.27724985e+03  1.91628781e+02  9.59995079e+02\n",
      "  3.93494602e+02  5.73166732e+02  1.90430612e+03  1.00084480e+03\n",
      "  9.30977201e+02  5.37399299e+02  4.83756347e+02  1.57918008e+03\n",
      "  4.10761643e+02  1.16509393e+03  1.08461683e+03  5.21165563e+02\n",
      "  1.15416780e+03  1.28073201e+03  1.26569015e+03  5.20963266e+02\n",
      "  4.37702360e+02  4.47679957e+02  8.86157272e+02  3.92993921e+02\n",
      "  6.79874787e+02  5.58554710e+02  1.25057298e+03  8.01952916e+02\n",
      "  1.73850318e+03  1.16439098e+03  4.51310088e+02  4.53287127e+02\n",
      "  5.54635809e+02 -3.25231852e+01  7.34197076e+02  1.93261664e+03\n",
      "  5.33331643e+02  9.05691387e+02  1.05181094e+03  5.49912789e+02\n",
      "  2.40379470e+02  7.57142936e+02  5.23959592e+02  2.67918781e+03\n",
      "  2.02711646e+02  2.28238322e+02  3.32507357e+03  4.64953527e+02\n",
      "  1.51800841e+03  4.55338679e+02  1.16040976e+03  1.62149126e+03\n",
      "  1.90886180e+03  5.52657806e+02  2.42527680e+03  7.82959512e+02\n",
      "  9.76833474e+02  4.36788080e+02  1.15576108e+03 -1.37618922e+02\n",
      "  7.86328793e+02  5.54635809e+02  1.62169596e+03  4.30675180e+02\n",
      "  1.15066766e+03  4.46192823e+02  8.04060668e+02  4.59521473e+02\n",
      "  2.61069503e+02  4.19305581e+02  8.42162926e+02  2.87857465e+02\n",
      "  1.93757572e+03  2.74417576e+02  4.50732891e+02  7.12454143e+02\n",
      "  1.02687892e+03  1.11447302e+03  8.71272953e+02  4.50732891e+02\n",
      "  5.54635809e+02  1.01255540e+03  4.48277194e+02  1.23070610e+03\n",
      "  7.86934254e+02  1.54263712e+01  4.50732891e+02  8.38556797e+02\n",
      "  3.11965885e+02  5.78555250e+02  2.46183633e+03  1.41039139e+02\n",
      "  1.32137874e+02  1.04071862e+03  3.29823916e+02  5.13195959e+02\n",
      "  1.00581244e+03  6.34869311e+02  2.19002766e+02  6.04879987e+02\n",
      "  9.32931472e+02  7.71674021e+02  5.61865220e+02  1.01699587e+03\n",
      "  1.19596988e+03  1.10923887e+03  1.07826641e+03  4.37144170e+02\n",
      "  1.05449505e+03  7.43885145e+02  1.23037599e+03  4.81809442e+02\n",
      "  1.11311337e+03  4.50732891e+02  3.72913410e+02  7.71674021e+02\n",
      "  1.22284724e+03  5.14532088e+02  1.33124648e+03  5.61558448e+02\n",
      "  1.17046120e+03  7.00818555e+02  7.01917697e+02  1.46934236e+03\n",
      "  1.21780708e+03  9.84619486e+02  9.20314530e+02  8.93311211e+02\n",
      "  1.73580848e+02  9.18916667e+02  9.44242075e+02  4.00015273e+02\n",
      "  1.38191482e+03  8.15430515e+02  5.61558448e+02  5.67510002e+02\n",
      "  1.32585466e+03  4.50732891e+02  4.90470778e+02  8.31030744e+02\n",
      "  3.11314200e+02  4.48642643e+02  5.43426812e+02  4.59273338e+02\n",
      "  1.82625892e+03  1.08328838e+03  2.83504552e+02  6.16508025e+02\n",
      "  7.32769199e+02  7.91757246e+02  9.64513130e+02  5.83046059e+02\n",
      "  7.18520844e+02  1.16010817e+03  6.64132968e+02  8.42162926e+02\n",
      "  1.05644368e+03  1.84096103e+03  2.06828404e+02  9.48067285e+02\n",
      "  3.69477212e+02  4.21063915e+02  1.62229166e+03  5.49912789e+02\n",
      "  1.23001239e+03  4.72796693e+02  1.13126785e+03  5.29092854e+02\n",
      "  8.01389863e+02  8.47855986e+02  2.24550758e+03  1.41837284e+03\n",
      "  2.93593212e+02  7.77523060e+02  9.00467925e+02  7.51574883e+02\n",
      "  6.79876734e+02  2.20301862e+02  6.71689666e+02  5.84033895e+02\n",
      "  5.78979860e+02  3.79305762e+02  2.87857465e+02  8.01952916e+02\n",
      "  1.55022808e+03  5.49912789e+02  8.11279772e+02  2.35696607e+03\n",
      "  1.10620170e+03  5.32914567e+02  1.10940880e+03  4.94136324e+02\n",
      "  1.13338089e+03  1.53123978e+03  3.15480877e+02  8.77918747e+02\n",
      "  5.72452183e+02  3.46638300e+02  9.71212459e+02  8.94360965e+02\n",
      "  1.42147316e+03  5.76260232e+02  4.68010155e+02  1.51118589e+03\n",
      "  7.58451730e+02  4.01127646e+02  9.28928286e+02  4.49559849e+02\n",
      "  1.26346918e+03  8.12300723e+02  6.81500317e+02  1.78634571e+03\n",
      "  1.54499917e+03  6.96923060e+02  3.46984360e+01  2.74417576e+02\n",
      "  9.78350025e+02  5.63800893e+02  4.49294840e+02  1.25137602e+03\n",
      "  8.43256915e+02  1.03882518e+03  8.65339936e+02  4.69298495e+02\n",
      "  6.12411646e+02  1.15576108e+03  2.17148519e+01  5.39404199e+02\n",
      "  4.64728984e+02  8.57930932e+02  4.34405188e+02  8.43014066e+02\n",
      "  2.40176617e+02  8.38221813e+02  2.00582231e+03  9.31429928e+02\n",
      "  1.26569015e+03  1.10031766e+03  4.00967950e+02  4.29197962e+02\n",
      "  1.53520663e+03  3.77141992e+02  3.34373383e+02  1.70884931e+03\n",
      "  1.86676181e+03  5.13259754e+02  2.20908049e+02  5.61558448e+02\n",
      "  7.47933330e+02  4.78004085e+02  4.68792297e+02  8.59606464e+02\n",
      "  1.08461683e+03  3.82814387e+02  4.13384810e+02  6.03350494e+02\n",
      "  5.23964738e+02  1.04459376e+03  7.33419831e+02  1.20384932e+03\n",
      "  4.50732891e+02  3.51998910e+02  1.82901398e+03  7.58070506e+02\n",
      "  7.00818555e+02  1.20050935e+03  5.56001456e+02  1.57584434e+03\n",
      "  1.19067680e+03  1.07831106e+03  3.36747044e+02  1.29549104e+03\n",
      "  5.61558448e+02  7.10468731e+02  8.01634196e+02  1.16142361e+03\n",
      "  8.13471740e+02  1.23236413e+03  8.10499006e+02  2.73205572e+02\n",
      "  6.91309469e+02  4.85428669e+02  9.63009071e+02  9.05691387e+02\n",
      "  8.76801540e+02  8.19554814e+02  1.01934785e+03  1.21894977e+03\n",
      "  9.00679076e+02  5.58643958e+02  2.82270652e+02  1.01529070e+03\n",
      "  6.85208979e+02  7.79466150e+02  1.17986795e+03  7.43486848e+02\n",
      "  1.10923887e+03  8.01952916e+02  1.22817634e+03  5.36430866e+02\n",
      "  7.64812664e+02  1.16936312e+03  1.97032287e+02  2.26878028e+02\n",
      "  6.85458972e+02  5.39330990e+02  2.12478845e+03  4.78739949e+02\n",
      "  3.11025431e+02  5.38167109e+02  1.19232175e+03  8.07441129e+02\n",
      "  4.94899938e+02  1.33130710e+03  8.41996729e+02  3.81266689e+02\n",
      "  2.57437569e+02  3.64205532e+02  1.09924485e+03  6.37558878e+02\n",
      "  5.40160059e+02  7.09702530e+02  1.68328051e+03  3.87978374e+02\n",
      "  1.15801226e+03  9.11338482e+02  9.62778467e+02  5.23439955e+02\n",
      "  2.28758142e+02  4.50732891e+02  5.25032285e+02  4.43798993e+02\n",
      "  6.06250028e+02  4.45215607e+02  2.42378257e+02  1.94890356e+03\n",
      "  4.13169600e+02  2.32742755e+03  1.03616053e+03  1.03871999e+03\n",
      "  1.90886180e+03  8.42162926e+02  2.12889295e+03  1.25945633e+03\n",
      "  6.73199200e+02  8.91732562e+02  1.50151360e+02  3.31933382e+02\n",
      "  5.49912789e+02 -6.45901008e-01  5.54635809e+02  8.76414973e+02\n",
      "  2.54634040e+03  3.82767949e+02  8.23988587e+02  7.81659576e+02\n",
      "  4.47478578e+02  8.73410038e+02  1.24390121e+03  2.93716944e+03\n",
      "  1.44461606e+03  1.96247359e+03  1.12488579e+02  7.69270606e+02\n",
      "  1.11221589e+03  1.06043713e+03  5.33829178e+02  1.00184075e+03\n",
      "  1.29652651e+03  4.91043666e+02  1.07826641e+03  2.91538189e+02\n",
      "  1.04654857e+03  9.92096764e+02  5.68581748e+02  2.43050417e+03\n",
      "  1.43037802e+02  8.20407618e+02 -2.02813150e+01  1.98451592e+03\n",
      "  1.17986795e+03  1.18712625e+03  5.37024093e+02  7.42085163e+02\n",
      "  5.88567033e+02  2.34234289e+03  1.78472233e+03  9.14449770e+02\n",
      "  2.74417576e+02  2.09220972e+03  4.53420434e+02  4.13169600e+02\n",
      "  4.35976548e+02  1.20383517e+03  9.75755257e+02  9.44935963e+02\n",
      "  8.01834516e+02  4.93528531e+02  7.53313093e+02  2.54398880e+03\n",
      "  6.96045736e+02  5.64428795e+02  1.83893354e+03  4.33906263e+02\n",
      "  4.70351989e+02  2.45448868e+03  5.56001456e+02  4.77000333e+02\n",
      "  1.42475329e+03  7.29071546e+02  6.90111025e+02  9.46292248e+02\n",
      "  1.99162966e+03  4.64938520e+02  8.07758441e+02  1.35235478e+03\n",
      "  4.13384810e+02  1.05560142e+03  4.36063221e+02  2.32986201e+02\n",
      "  8.62782587e+02  2.08992654e+03  4.40852283e+02  1.00054372e+03\n",
      "  8.33122790e+02  5.96172169e+02  7.68321497e+02 -1.40711031e+02\n",
      "  7.74892429e+02  1.02416412e+03  4.49294840e+02  1.00054372e+03\n",
      "  5.52209672e+02  1.86254278e+03  3.78698015e+02  7.34336247e+02\n",
      "  1.93261664e+03  3.65376620e+02  9.19616544e+02  4.46415787e+02\n",
      "  9.57152530e+02  6.80373006e+02  4.48631014e+02  1.12353712e+03\n",
      "  3.87360539e+02  1.76036384e+03  1.33753168e+03  1.34624694e+03\n",
      "  9.61370837e+02  6.77487864e+02  9.30370292e+02  8.86293380e+02\n",
      "  1.23717224e+03  2.34516375e+03  9.27534278e+02  1.10923887e+03\n",
      "  5.54635809e+02  5.42802750e+02  1.03291362e+03  1.40165736e+03\n",
      "  2.74369610e+03  5.82869170e+02  1.38619509e+03  8.58532675e+02\n",
      "  4.37183466e+02  6.11702647e+02  7.73718641e+02  1.10925958e+03\n",
      "  1.48221959e+03  2.55479251e+02  4.13169600e+02  8.81478714e+02\n",
      "  5.54635809e+02  5.42802750e+02  5.60671961e+02  7.33140486e+02\n",
      "  4.03648880e+02  7.63169974e+02  1.35562758e+03  1.16509393e+03\n",
      "  4.55793241e+02  1.08858268e+03  6.00602401e+02  7.04123885e+02\n",
      "  4.69756766e+02  4.13169600e+02 -2.46630804e+02  2.74416289e+02\n",
      "  2.04548635e+03  1.11082149e+03  3.82948581e+02  1.82222155e+03\n",
      "  1.20045261e+03  4.37144170e+02  5.99542196e+02  3.52437196e+02\n",
      "  4.45273078e+02  5.81583568e+02  1.03396538e+03  6.69544222e+02\n",
      "  5.48701910e+02  9.27573586e+02 -2.46630804e+02  5.16859149e+02\n",
      "  3.97676514e+02  7.36355285e+02  1.00389082e+03  5.33246880e+02\n",
      "  4.68712750e+02  5.61883745e+02  4.56277277e+02  9.32618321e+02\n",
      "  4.58915126e+02  2.39993238e+02  7.18190742e+02  7.32957950e+02\n",
      "  1.00309871e+03  1.05181094e+03  1.18495650e+03  5.61558448e+02\n",
      "  8.01737576e+02  1.88268384e+03  1.10509696e+03  8.94108196e+02\n",
      "  1.38619509e+03  1.11221589e+03  1.03396667e+03  4.28871320e+02\n",
      "  1.08931333e+03  1.23220774e+03  8.16776474e+02  1.31536970e+03\n",
      "  8.94364586e+02  1.58918822e+03  3.41553408e+02  7.55595883e+02\n",
      "  4.50732891e+02  4.37013343e+02  3.07803094e+02  8.56439826e+02\n",
      "  4.37284911e+02  9.70301092e+02  5.11366074e+02  4.74588969e+02\n",
      "  1.06551277e+03  3.10878947e+02  3.97878371e+02  1.15082459e+03\n",
      "  5.24561317e+02  7.24524244e+02  2.34762835e+03  8.80008326e+02\n",
      "  1.36272714e+03  1.37472883e+03  4.13017629e+02  4.13169600e+02\n",
      "  2.46002729e+03  4.10202163e+02  4.35446183e+02  2.11818266e+03\n",
      "  8.42871047e+02  9.09942948e+02  4.55593922e+02  7.84554187e+02\n",
      "  1.14124646e+03  4.13169600e+02  9.25232097e+02  7.12500426e+02\n",
      "  8.60221412e+02  9.09815387e+02  4.68537048e+02  4.79233135e+02\n",
      "  4.58563847e+02  1.17986795e+03  1.84861733e+03  1.21051846e+03\n",
      "  4.47266703e+02  8.81029180e+02  3.28739298e+02  2.93554358e+02\n",
      "  1.00794984e+03  3.28739298e+02  4.97468749e+02  4.12940449e+02\n",
      "  8.23104902e+02  4.13384810e+02  1.19364466e+03  8.84094144e+02\n",
      "  6.29043302e+02  7.89772236e+02  1.15914600e+03  2.26109958e+03\n",
      "  1.76781072e+02  8.55744021e+02  6.31124504e+02  5.25032285e+02\n",
      "  3.28739298e+02  1.22053675e+03  3.88454089e+02  1.15576108e+03\n",
      "  1.28239912e+03  1.85770894e+03  3.80287913e+02  2.68385666e+02\n",
      "  5.82533611e+02  4.22926877e+02  1.31406488e+03  6.00470499e+02\n",
      "  6.41733995e+02  9.92864073e+02  1.98903261e+03]\n",
      "Actual values: [4149.99  719.99  479.88 1115.88  767.88  704.16  453.49  562.   1049.\n",
      "  298.85  369.99  548.    329.99  382.61 1089.    499.    399.99  219.\n",
      "  899.    999.    569.99  746.99  743.88  467.88  199.99  459.83  469.98\n",
      "  829.99  679.   2599.99  399.99  749.99  318.98 1439.99 2099.    689.99\n",
      "  537.48  599.99  160.07  299.    677.88 1028.35  969.41  699.99  949.99\n",
      "  209.99  189.99  399.   1399.99  469.    585.99  520.71  439.99  809.99\n",
      "  347.88  569.99 2799.99  587.88 2589.99 1772.95  229.9  1089.99  699.99\n",
      "  679.99 1249.99  199.   1449.99  799.   1128.    599.95  449.99 1169.99\n",
      " 1399.99  409.99 1489.99  538.99 1399.99  212.75  845.98  671.88 1599.\n",
      "  349.99 1019.88  589.99 1377.99  402.    595.   1919.88 2499.99 1149.99\n",
      "  698.99  749.99  644.95  149.99  599.99  928.   1309.99 1064.99  599.99\n",
      "  399.93  579.99  589.    548.   1049.    286.95  110.99 1199.    959.99\n",
      " 1409.99  791.88 2499.99  947.49  459.   1899.99  639.    527.88  999.99\n",
      "  719.88  969.99  743.88  799.99  209.6   779.   1299.   1149.65  925.\n",
      "  338.69 1128.    575.88  565.    899.    455.88  575.88 1299.99  443.88\n",
      " 1051.99  508.97  635.88  228.99  969.99  899.    409.99  539.88 1349.99\n",
      "  299.99  234.41  320.    969.03 1359.99  719.99  149.99  259.99  567.98\n",
      "  454.    439.24  287.    499.99  310.   1499.99  979.95  818.   1149.\n",
      "  749.99 1378.    258.   2399.99  269.99 1472.5   289.99  839.88 2389.99\n",
      " 1059.99 1079.88  719.31  649.99 1662.99  319.    799.99 1139.99  322.88\n",
      "  789.94 1159.99 1349.99  629.    287.88  284.99  799.99  499.    679.99\n",
      "  419.   1629.99 1115.88 1349.99 1519.99  150.69  172.98  743.88   60.\n",
      "  683.9  1739.99  640.99  969.    969.41  549.99  249.99  519.   1509.99\n",
      " 1299.    299.    202.79 5496.    586.96 2649.99  599.   1139.99 1599.99\n",
      " 1079.88  399.   1799.99 1269.99 1049.99  229.   1089.     63.99  749.\n",
      "  743.88 1237.49  285.99 2799.    999.    744.98  149.99  309.    219.69\n",
      "  928.    359.99 1599.9   409.99  455.88  487.   2279.88 2399.88  579.99\n",
      "  455.88  743.88  799.    217.69 1799.    283.99   59.55  455.88 2609.99\n",
      "  279.99  347.99 1599.99   89.    208.5   359.99  335.99  499.99  899.\n",
      "  459.99  219.    559.    581.95  511.15  199.9   899.   1199.99 1099.99\n",
      " 1029.    443.88 1319.99  599.99 2059.99  683.   1239.95  455.88  799.99\n",
      "  552.65  943.59  383.88  999.99  443.88  349.24  689.99  674.39 1522.68\n",
      " 1609.    929.   4999.99  767.88  184.99 1199.   1399.99  399.99 1249.\n",
      "  499.    443.88  590.28 1089.99  455.88  215.    835.    400.99   51.9\n",
      "  499.99  399.   1389.    871.19  383.88  399.99  199.   1799.99  789.\n",
      "  575.88  498.8   451.87  599.88  928.    859.   2199.99  204.    898.85\n",
      "  390.    529.99 2199.99  549.99 1709.     59.99  846.98  232.    265.\n",
      "  685.99 2199.99 1999.99  335.    276.88 1439.99  399.    695.88  229.98\n",
      "  461.66  849.99  599.    499.99  359.99 1115.88 1249.99  549.99  224.99\n",
      " 1297.    720.    407.15 1739.99  150.    129.99 1049.99  371.88  584.99\n",
      "  419.88  479.98  849.    899.99 1949.99  869.    399.99 1019.99  700.99\n",
      "  438.99  890.99  495.92 1039.99  623.88  639.   2428.99 1549.99  443.88\n",
      "   58.95  409.99 1219.99  319.99  399.99 1179.99  519.99 1511.88  503.8\n",
      "  407.88  269.99 1089.     93.98  359.99  149.   1055.88  296.99  799.99\n",
      "  359.99  349.99  749.    498.   1394.99  799.    679.99  439.93 2499.99\n",
      "  289.99  413.   1499.88 1426.99  498.88  289.    443.88  699.99  449.85\n",
      "  329.99 2199.   1139.99  161.99  359.88  799.99  549.99  949.99  719.\n",
      " 1599.99  455.88  274.99 1099.    695.88  689.99 1329.99  527.88 1659.99\n",
      "  814.99 1199.    239.99 1457.    443.88  583.99  559.99  999.98  539.\n",
      "  999.99 1499.99  269.99  443.88  729.99  699.    969.    859.99  670.72\n",
      "  408.98 1259.99  698.28  639.    199.99  899.    455.88  799.99  899.99\n",
      "  449.99 1099.99 1115.88 1299.99  799.99  239.   1429.    279.98  269.\n",
      "  439.24  390.99 3799.99  699.    383.88  379.99 1259.88  599.99  549.99\n",
      " 1399.99 1399.99  365.99  548.99  349.    679.    589.    519.    499.99\n",
      " 1999.    399.    799.99 1171.   1299.99  498.99  295.    455.88  419.88\n",
      "  343.99  903.6   839.99  399.   2799.99  479.97 2399.99 1319.    895.\n",
      " 1079.88  928.   2581.05  820.    459.83  741.51  282.    227.88  549.99\n",
      "   98.99  743.88 2159.88 2510.99  339.99  620.    375.99  549.    189.99\n",
      " 1399.99 2609.99 1618.8  2199.99  169.99 1139.88  879.99  639.    399.\n",
      "  462.   1399.99  399.99 1029.    209.    999.99  745.    629.99 2199.\n",
      "  159.    560.     99.99 1699.99  899.99 1099.99  169.5   529.99  718.8\n",
      " 3049.99 2399.99  799.99  409.99 1899.99   74.    323.98  579.99 1099.99\n",
      " 1659.   1759.    683.69  699.    349.    520.    146.74  440.   1999.99\n",
      "  359.    699.99 3290.99  527.88   65.99 1439.99  539.88  610.68 1128.\n",
      " 2299.99  449.99  579.   1139.    359.88 1499.    449.    149.    949.99\n",
      " 3699.    789.77  799.99  964.99  399.99  799.99  131.88  515.88  899.\n",
      "  753.99  799.99  819.   1599.99  799.99  827.88 3149.99  219.99 1223.99\n",
      "  219.   1129.96  649.99  549.99  799.99  269.99 2078.99 1285.   1059.\n",
      "  779.88  579.   1128.    919.99 1559.   2799.99  449.99 1099.99  743.88\n",
      "  659.88 1580.   3395.88 2599.99  599.88 1127.88 1799.99  489.97  585.99\n",
      "  666.99 1649.99  469.    349.99  479.97 1096.98  743.88  659.88  263.99\n",
      " 1099.99  679.99  599.99 1499.99  799.99  398.   1249.99  899.99  239.\n",
      "  254.99  323.98   59.99  409.99 1599.99  829.    539.9  1749.99 1409.\n",
      "  443.88  549.    329.99  199.9   677.   1889.99  549.99  309.99  649.8\n",
      "   63.98  658.79  649.99  797.74  995.88  749.99  649.99  459.99  809.99\n",
      "  639.    239.    239.88  635.9   599.99  839.99  969.41  619.99  443.88\n",
      "  560.    959.99  880.    699.   1127.88  929.99 1499.99  329.99 1019.99\n",
      "  977.99 1099.99 1299.99 1999.99 2099.    395.99  739.99  455.88  289.98\n",
      "  339.68 1229.99  219.99 1489.99  599.99  679.49  839.    335.    219.\n",
      " 1099.    439.99  169.99 2799.99  639.99 1299.99 1399.99  139.    479.97\n",
      " 2299.    316.    169.99 3666.99  799.    567.98  439.24  685.    959.88\n",
      "  323.98  776.99  949.99  249.99 1099.99  989.99  499.    489.99  899.99\n",
      " 1899.   1499.99  683.88  569.99  335.88  199.   1399.99  335.88  499.99\n",
      "  154.58  429.99  359.88 1772.95 1149.99  601.6  1099.99  719.99 2699.99\n",
      "  197.99  825.    623.88  419.88  335.88  999.    166.48 1029.   1349.99\n",
      " 1999.99  279.    369.99  359.99  483.   1349.99  649.99 1599.99  587.88\n",
      " 1649.  ]\n",
      "Root Mean Squared Error: 412.96093548715976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "categorical_cols = ['Brand', 'Processor_Brand', 'Operating_System', 'Storage_Type', 'Processor_Model']\n",
    "numerical_cols = ['Extracted_Rating', 'Storage_Capacity(GB)', 'Display_Size(Inches)', 'RAM(GB)', 'No_Of_Reviews', 'Laptop_Weight(Pounds)', 'Price']\n",
    "\n",
    "laptop_df_cleaned = laptop_df_cleaned.dropna(subset=['Price'])\n",
    "\n",
    "X = laptop_df_cleaned[categorical_cols + numerical_cols[:-1]]  # Exclude Price from features\n",
    "y = laptop_df_cleaned['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_cols[:-1]),  # Exclude 'Price'\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Predicted values:\", y_pred)\n",
    "print(\"Actual values:\", y_test.values)\n",
    "print(\"Root Mean Squared Error:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4abbcf4-62fd-481f-9722-66726fe067c7",
   "metadata": {},
   "source": [
    "# 4. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b55c4-718f-40ed-9770-e4c12840714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store prediction of each model and the trained model object\n",
    "y_pred_reg_models = []\n",
    "reg_model = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897878b-d04e-40ff-854a-87a423ba0a0f",
   "metadata": {},
   "source": [
    "## 4.1 KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "77410030-d898-4022-89b4-ed4dcd4e4c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [1437.438  778.19   863.326 1046.28  1046.28   761.714  700.68   650.182\n",
      " 1195.868  415.392  379.972  740.17   319.39   387.562 1085.164  499.\n",
      "  369.99   186.392 1063.794  819.53   441.124 1114.716  734.28   615.216\n",
      "  297.996  459.83   455.988  603.982  605.6   2266.842  342.18   921.946\n",
      "  419.754 1325.99  1801.594  650.056  670.678  415.392  256.998  212.97\n",
      " 1095.772  931.594 1132.458  615.216  676.434  606.388  409.17   348.664\n",
      " 1405.594  395.17   650.182  674.522  261.99   281.5    359.88   581.99\n",
      "  992.842  700.68  3988.96  1380.384  839.196 1158.03   557.396  654.458\n",
      " 2313.494  183.684 2329.792 1211.666 1128.    2453.596  379.972 1263.792\n",
      "  863.326  409.756 1494.39   388.378  939.984  209.348  971.404  761.714\n",
      " 1063.164  397.99   656.328  539.812 1358.552  527.898  839.232 1388.804\n",
      " 2072.19   939.792  631.596  827.99   863.326  221.792  513.16   928.\n",
      "  761.714 2453.596  650.182  696.384  742.64   605.6    573.552 1132.458\n",
      "  286.784  374.532 1132.458 1893.59   817.382  777.902 1114.716 2241.434\n",
      "  344.332 1625.79   784.872  615.216  644.792  806.28  1263.792  734.28\n",
      " 1039.99   696.384  831.29  1271.576  784.872 1068.342  930.386 1128.\n",
      "  558.304  597.51  3110.97   426.054  558.304 1629.792  552.702 1322.638\n",
      "  644.792  734.28   259.598  301.774 1090.574  409.756  576.504 1295.792\n",
      "  427.792  202.428  307.488  971.404  908.066  481.774  379.972  785.076\n",
      "  615.948  971.994  439.24   971.404  441.124  412.082 2089.792  847.988\n",
      "  971.404 1158.03  1066.042 1228.592  573.552 1188.394  198.386  839.232\n",
      "  450.19   761.714 1257.368  778.946  880.112  650.182  441.124 1269.99\n",
      "  241.796  839.99  1282.792  422.326  785.238 1137.544 1670.196  395.94\n",
      "  844.548  379.972 1113.     319.396  625.792  405.718 1338.028 1046.28\n",
      " 1239.99  1005.99   286.462  359.986  734.28   169.178  720.234 1437.438\n",
      "  508.008  766.174 1085.164  549.99   327.99   654.458  594.994 1821.792\n",
      "  294.886  212.998 3211.992  650.182 1955.99   569.594 1057.792 1249.792\n",
      " 1606.574  405.718 1195.546  839.232 1103.222  217.198 1132.458  132.796\n",
      "  839.196  734.28  1349.524  594.994 1454.262  359.986  839.196  386.296\n",
      "  301.     465.772  928.     319.39  2241.434  409.756  426.054  557.396\n",
      " 1515.122 1346.978  859.388  426.054  734.28  1161.174  457.446  908.066\n",
      "  921.946  152.396  426.054 1893.59   382.2    509.09  2140.556  173.552\n",
      "  209.116  843.99   423.27   447.324 1068.342  727.592  312.794  602.06\n",
      "  863.326  557.396  761.714 1100.996 1139.592 1099.99  1085.164  441.48\n",
      " 1019.19   757.792 2151.394  512.1   1166.796  426.054  261.99   557.396\n",
      " 1359.99   521.924 1502.458  552.702  980.794  557.396  725.638 1330.086\n",
      " 1369.22   905.     954.792 1046.28   229.592  971.404 1078.012  369.99\n",
      " 1322.638  552.408  552.702  761.714 1158.03   426.054  761.714  737.506\n",
      "  315.398  136.776  582.596  502.794 1385.392 1271.576  526.132  542.782\n",
      "  839.196  644.792 1211.666  558.304  557.396  785.238  606.06   928.\n",
      " 1116.996 2553.99   242.798  901.392  338.57   569.99  1547.99   549.99\n",
      " 1271.198   82.546  867.59   457.446  971.404  640.186 2461.148 1439.392\n",
      "  297.686  696.384 1376.39   971.994  734.28   187.558  523.954  700.68\n",
      "  582.596  374.084  319.39  1046.28  1217.99   549.99   687.792 2327.168\n",
      "  839.99   407.15  1039.99   374.532 1427.99  1209.99   471.528 1289.22\n",
      "  422.28   419.754  613.15   737.506 1315.99   761.714  359.986 1117.99\n",
      "  819.53   374.532  859.388  433.798  908.066 1199.968  567.396 1833.99\n",
      " 1249.792  501.48   152.396  409.756 1349.39   481.774  468.428 1384.992\n",
      "  720.234 1346.978  603.982  433.798  255.99  1132.458   72.532  732.786\n",
      "  374.532  863.326  468.428  791.19   203.792  803.594  907.08   931.792\n",
      " 1670.196  839.99   230.79   409.756 1955.99   415.392  366.756 1414.404\n",
      " 1390.568  692.152  420.936  552.702  557.396 1398.872  419.88   687.792\n",
      " 1282.792  457.446  359.88   509.928  594.994  720.108  696.384  908.066\n",
      "  426.054  415.392 1534.596  727.948  557.396 1008.572  615.216 1352.084\n",
      "  929.924 1085.164  315.398 1128.968  552.702  640.186  681.614 1044.982\n",
      "  681.614  929.924  865.792  307.488  443.88   374.532  839.232  766.174\n",
      "  778.19   720.234  641.132 1046.19   971.404  666.99   207.98  1090.574\n",
      "  455.88   799.99   961.298  494.936 1099.99  1046.28   908.066  635.184\n",
      "  246.996 1066.22   310.194  242.584  439.24   631.394 3055.598  508.008\n",
      "  368.256  773.99  1182.826  605.432  379.972  912.788  839.232  407.594\n",
      "  407.594  314.466 1062.86   556.572  441.198  839.196 1029.992  419.754\n",
      "  839.99  1068.342  848.292  643.942  188.508  426.054  700.68   457.446\n",
      "  700.68   457.446  333.886 2159.99   417.574 2899.792  569.544  683.764\n",
      " 1606.574  928.    1920.834  973.546  459.83   746.398  242.584  267.844\n",
      "  549.99    77.93   734.28  1231.794 2553.99   379.972 1514.748  640.186\n",
      "  615.948  579.792 1384.992 2764.394 1494.086 1349.99   187.99   721.902\n",
      "  961.298 1597.024  650.056  514.24  1033.198  508.974 1085.164  242.798\n",
      " 1325.99  1271.576  740.17  2227.194  191.296  977.768   87.558 2071.336\n",
      "  961.298 1143.192  594.994  839.196  700.68  2908.99  1383.156  580.294\n",
      "  409.756 2332.764   67.578  417.574  379.972  908.066 1271.576  665.396\n",
      "  720.234  569.594  644.792 1573.81   349.494  508.974  717.786  238.812\n",
      "  359.986 2582.19   615.216   67.578 1494.39   777.902  725.638 1128.\n",
      " 1515.126  727.592  641.286 1158.03   359.88  1299.934  538.596  214.214\n",
      "  921.946 1938.346  457.446  848.688  863.326  654.2    819.53   176.368\n",
      "  777.902  961.298  468.428  848.688  650.182 1883.     624.324  727.948\n",
      " 1437.438  339.384 1078.012  468.428 1271.576  523.954  441.124  961.298\n",
      "  489.792 2553.99  1158.03  1988.544  676.084  654.458 1128.     819.53\n",
      " 1193.218 2899.792  971.404 1099.99   734.28   700.68  1281.372 1274.148\n",
      " 3639.99   600.524 1107.92   579.792  546.59   465.58   469.99  1039.99\n",
      "  663.974  489.792  417.574 1090.574  734.28   700.68   280.664  966.376\n",
      "  606.388  977.768 1979.99   839.99   588.544 1166.796  255.99   323.192\n",
      "  359.986  417.574  242.798  409.756 1687.99   880.112  512.1   1390.568\n",
      " 2427.77   441.48   482.478  347.99   650.182  650.182 1166.796  734.28\n",
      "  594.994 1090.574  242.798  615.948  489.052  654.458  808.542  491.208\n",
      "  606.388  615.216  281.5    998.992  650.182  347.88   784.872  848.568\n",
      " 1005.99  1085.164  689.584  552.702  711.67   731.99  1282.792  681.614\n",
      " 1107.92   961.298 1166.796  415.392  893.99  1384.992  977.768  912.788\n",
      " 1351.99  1296.99   423.27   780.592  426.054  286.994  407.594  971.404\n",
      "  388.75  1068.342  581.99   761.714  880.112  418.824  197.592 1057.792\n",
      "  379.972  696.384 2229.99   707.99  1135.968 1629.792  374.532  417.574\n",
      " 2227.194  419.152  359.986 2266.842  931.594  576.504  439.24   683.198\n",
      "  876.234  417.574  859.388  641.286  535.99   823.982  439.852  508.974\n",
      "  359.986  961.298 1218.824 1352.296  615.948 1199.968  368.256  239.918\n",
      "  968.794  368.256  441.124  374.532  551.992  359.88  1772.95   859.388\n",
      "  605.6    827.99   980.794 2899.792  174.79   977.768  761.714  700.68\n",
      "  368.256 1063.794  457.446 1132.458 1399.396 1689.99   200.836  472.99\n",
      "  732.786  415.392  995.428  558.304  507.96   557.594 1827.   ]\n",
      "Actual values: [4149.99  719.99  479.88 1115.88  767.88  704.16  453.49  562.   1049.\n",
      "  298.85  369.99  548.    329.99  382.61 1089.    499.    399.99  219.\n",
      "  899.    999.    569.99  746.99  743.88  467.88  199.99  459.83  469.98\n",
      "  829.99  679.   2599.99  399.99  749.99  318.98 1439.99 2099.    689.99\n",
      "  537.48  599.99  160.07  299.    677.88 1028.35  969.41  699.99  949.99\n",
      "  209.99  189.99  399.   1399.99  469.    585.99  520.71  439.99  809.99\n",
      "  347.88  569.99 2799.99  587.88 2589.99 1772.95  229.9  1089.99  699.99\n",
      "  679.99 1249.99  199.   1449.99  799.   1128.    599.95  449.99 1169.99\n",
      " 1399.99  409.99 1489.99  538.99 1399.99  212.75  845.98  671.88 1599.\n",
      "  349.99 1019.88  589.99 1377.99  402.    595.   1919.88 2499.99 1149.99\n",
      "  698.99  749.99  644.95  149.99  599.99  928.   1309.99 1064.99  599.99\n",
      "  399.93  579.99  589.    548.   1049.    286.95  110.99 1199.    959.99\n",
      " 1409.99  791.88 2499.99  947.49  459.   1899.99  639.    527.88  999.99\n",
      "  719.88  969.99  743.88  799.99  209.6   779.   1299.   1149.65  925.\n",
      "  338.69 1128.    575.88  565.    899.    455.88  575.88 1299.99  443.88\n",
      " 1051.99  508.97  635.88  228.99  969.99  899.    409.99  539.88 1349.99\n",
      "  299.99  234.41  320.    969.03 1359.99  719.99  149.99  259.99  567.98\n",
      "  454.    439.24  287.    499.99  310.   1499.99  979.95  818.   1149.\n",
      "  749.99 1378.    258.   2399.99  269.99 1472.5   289.99  839.88 2389.99\n",
      " 1059.99 1079.88  719.31  649.99 1662.99  319.    799.99 1139.99  322.88\n",
      "  789.94 1159.99 1349.99  629.    287.88  284.99  799.99  499.    679.99\n",
      "  419.   1629.99 1115.88 1349.99 1519.99  150.69  172.98  743.88   60.\n",
      "  683.9  1739.99  640.99  969.    969.41  549.99  249.99  519.   1509.99\n",
      " 1299.    299.    202.79 5496.    586.96 2649.99  599.   1139.99 1599.99\n",
      " 1079.88  399.   1799.99 1269.99 1049.99  229.   1089.     63.99  749.\n",
      "  743.88 1237.49  285.99 2799.    999.    744.98  149.99  309.    219.69\n",
      "  928.    359.99 1599.9   409.99  455.88  487.   2279.88 2399.88  579.99\n",
      "  455.88  743.88  799.    217.69 1799.    283.99   59.55  455.88 2609.99\n",
      "  279.99  347.99 1599.99   89.    208.5   359.99  335.99  499.99  899.\n",
      "  459.99  219.    559.    581.95  511.15  199.9   899.   1199.99 1099.99\n",
      " 1029.    443.88 1319.99  599.99 2059.99  683.   1239.95  455.88  799.99\n",
      "  552.65  943.59  383.88  999.99  443.88  349.24  689.99  674.39 1522.68\n",
      " 1609.    929.   4999.99  767.88  184.99 1199.   1399.99  399.99 1249.\n",
      "  499.    443.88  590.28 1089.99  455.88  215.    835.    400.99   51.9\n",
      "  499.99  399.   1389.    871.19  383.88  399.99  199.   1799.99  789.\n",
      "  575.88  498.8   451.87  599.88  928.    859.   2199.99  204.    898.85\n",
      "  390.    529.99 2199.99  549.99 1709.     59.99  846.98  232.    265.\n",
      "  685.99 2199.99 1999.99  335.    276.88 1439.99  399.    695.88  229.98\n",
      "  461.66  849.99  599.    499.99  359.99 1115.88 1249.99  549.99  224.99\n",
      " 1297.    720.    407.15 1739.99  150.    129.99 1049.99  371.88  584.99\n",
      "  419.88  479.98  849.    899.99 1949.99  869.    399.99 1019.99  700.99\n",
      "  438.99  890.99  495.92 1039.99  623.88  639.   2428.99 1549.99  443.88\n",
      "   58.95  409.99 1219.99  319.99  399.99 1179.99  519.99 1511.88  503.8\n",
      "  407.88  269.99 1089.     93.98  359.99  149.   1055.88  296.99  799.99\n",
      "  359.99  349.99  749.    498.   1394.99  799.    679.99  439.93 2499.99\n",
      "  289.99  413.   1499.88 1426.99  498.88  289.    443.88  699.99  449.85\n",
      "  329.99 2199.   1139.99  161.99  359.88  799.99  549.99  949.99  719.\n",
      " 1599.99  455.88  274.99 1099.    695.88  689.99 1329.99  527.88 1659.99\n",
      "  814.99 1199.    239.99 1457.    443.88  583.99  559.99  999.98  539.\n",
      "  999.99 1499.99  269.99  443.88  729.99  699.    969.    859.99  670.72\n",
      "  408.98 1259.99  698.28  639.    199.99  899.    455.88  799.99  899.99\n",
      "  449.99 1099.99 1115.88 1299.99  799.99  239.   1429.    279.98  269.\n",
      "  439.24  390.99 3799.99  699.    383.88  379.99 1259.88  599.99  549.99\n",
      " 1399.99 1399.99  365.99  548.99  349.    679.    589.    519.    499.99\n",
      " 1999.    399.    799.99 1171.   1299.99  498.99  295.    455.88  419.88\n",
      "  343.99  903.6   839.99  399.   2799.99  479.97 2399.99 1319.    895.\n",
      " 1079.88  928.   2581.05  820.    459.83  741.51  282.    227.88  549.99\n",
      "   98.99  743.88 2159.88 2510.99  339.99  620.    375.99  549.    189.99\n",
      " 1399.99 2609.99 1618.8  2199.99  169.99 1139.88  879.99  639.    399.\n",
      "  462.   1399.99  399.99 1029.    209.    999.99  745.    629.99 2199.\n",
      "  159.    560.     99.99 1699.99  899.99 1099.99  169.5   529.99  718.8\n",
      " 3049.99 2399.99  799.99  409.99 1899.99   74.    323.98  579.99 1099.99\n",
      " 1659.   1759.    683.69  699.    349.    520.    146.74  440.   1999.99\n",
      "  359.    699.99 3290.99  527.88   65.99 1439.99  539.88  610.68 1128.\n",
      " 2299.99  449.99  579.   1139.    359.88 1499.    449.    149.    949.99\n",
      " 3699.    789.77  799.99  964.99  399.99  799.99  131.88  515.88  899.\n",
      "  753.99  799.99  819.   1599.99  799.99  827.88 3149.99  219.99 1223.99\n",
      "  219.   1129.96  649.99  549.99  799.99  269.99 2078.99 1285.   1059.\n",
      "  779.88  579.   1128.    919.99 1559.   2799.99  449.99 1099.99  743.88\n",
      "  659.88 1580.   3395.88 2599.99  599.88 1127.88 1799.99  489.97  585.99\n",
      "  666.99 1649.99  469.    349.99  479.97 1096.98  743.88  659.88  263.99\n",
      " 1099.99  679.99  599.99 1499.99  799.99  398.   1249.99  899.99  239.\n",
      "  254.99  323.98   59.99  409.99 1599.99  829.    539.9  1749.99 1409.\n",
      "  443.88  549.    329.99  199.9   677.   1889.99  549.99  309.99  649.8\n",
      "   63.98  658.79  649.99  797.74  995.88  749.99  649.99  459.99  809.99\n",
      "  639.    239.    239.88  635.9   599.99  839.99  969.41  619.99  443.88\n",
      "  560.    959.99  880.    699.   1127.88  929.99 1499.99  329.99 1019.99\n",
      "  977.99 1099.99 1299.99 1999.99 2099.    395.99  739.99  455.88  289.98\n",
      "  339.68 1229.99  219.99 1489.99  599.99  679.49  839.    335.    219.\n",
      " 1099.    439.99  169.99 2799.99  639.99 1299.99 1399.99  139.    479.97\n",
      " 2299.    316.    169.99 3666.99  799.    567.98  439.24  685.    959.88\n",
      "  323.98  776.99  949.99  249.99 1099.99  989.99  499.    489.99  899.99\n",
      " 1899.   1499.99  683.88  569.99  335.88  199.   1399.99  335.88  499.99\n",
      "  154.58  429.99  359.88 1772.95 1149.99  601.6  1099.99  719.99 2699.99\n",
      "  197.99  825.    623.88  419.88  335.88  999.    166.48 1029.   1349.99\n",
      " 1999.99  279.    369.99  359.99  483.   1349.99  649.99 1599.99  587.88\n",
      " 1649.  ]\n",
      "Root Mean Squared Error: 412.96093548715976\n"
     ]
    }
   ],
   "source": [
    "# KNN Regressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "\n",
    "KNNcategorical_cols = ['Brand', 'Processor_Brand', 'Storage_Type', 'Processor_Model']\n",
    "KNNnumerical_cols = ['Storage_Capacity(GB)', 'RAM(GB)', 'Price']\n",
    "\n",
    "KNN_df_cleaned = laptop_df_cleaned.dropna(subset=['Price'])\n",
    "\n",
    "X = KNN_df_cleaned[KNNcategorical_cols + KNNnumerical_cols[:-1]]  # Exclude Price from features\n",
    "y = KNN_df_cleaned['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_cols[:-1]), \n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "KNN_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', knn_regressor)\n",
    "])\n",
    "\n",
    "KNN_pipeline.fit(X_train, y_train)\n",
    "\n",
    "KNN_y_pred = KNN_pipeline.predict(X_test)\n",
    "\n",
    "KNNmse = mean_squared_error(y_test, KNN_y_pred)\n",
    "KNNrmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Predicted values:\", KNN_y_pred)\n",
    "print(\"Actual values:\", y_test.values)\n",
    "print(\"Root Mean Squared Error:\", KNNrmse)\n",
    "\n",
    "\n",
    "# knn_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# y_pred_knn_regressor = knn_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498f05b-22ae-48e1-b124-e15fdb0c6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_reg_models.append(y_pred_knn_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28399e9c-e1e1-4b74-a13a-ef6ce51b0ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_model.append(knn_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b3ea4-35f2-4e62-99ae-f39811a8c200",
   "metadata": {},
   "source": [
    "## 4.2 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197811e-acda-4aa4-b371-de92cd0b0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_decision_tree = decision_tree_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179c211-971c-41bd-a705-e1acd88a35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_models.append(y_pred_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c1b71-1a21-4f07-894e-ebdaa26e541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.append(decision_tree_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a336b-add8-4ecd-9e25-2b38c81a8c41",
   "metadata": {},
   "source": [
    "## 4.3 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebea1dc-fc7c-4c13-85bf-c342d08f6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regressor = LinearRegression()\n",
    "\n",
    "\n",
    "# Full pipeline with preprocessing and model\n",
    "LR_full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', linear_regressor)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "LR_full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "LR_y_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Predicted values:\", y_pred)\n",
    "print(\"Actual values:\", y_test.values)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "linear_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_linear = linear_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b64f9-c2ce-4a65-8fa9-f503d92010e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_models.append(y_pred_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770eec0-2cd8-40cb-b50e-bbfb33328fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.append(linear_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2945e639-d268-4407-a6d2-5dee2dcc046d",
   "metadata": {},
   "source": [
    "## 4.4 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337cf837-56e5-4e91-ad51-709ff64f7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_regressor = Ridge(alpha=1.0)\n",
    "ridge_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_ridge = ridge_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333770dd-2ef9-4889-ac6d-32d531182d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_models.append(y_pred_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f23ee-9d77-427c-a6b9-b8f316da904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.append(ridge_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb545bf-b651-4357-8f81-be677d5d3427",
   "metadata": {},
   "source": [
    "## 4.5 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4b495-7b3c-4590-8194-fd681fe56c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_regressor = Lasso(alpha=0.1)\n",
    "lasso_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lasso = lasso_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7429be3-4ce0-4b64-a177-ee676b50a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_models.append(y_pred_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d8f517-c0ea-4cfc-a7db-cde4efff1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.append(lasso_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a37d1-7dfb-4914-b575-df47d10fd3ca",
   "metadata": {},
   "source": [
    "## 4.6 RANSAC Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875ac36-4341-4303-9c4f-958ee703e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANSAC Regression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ransac_regressor = RANSACRegressor(estimator=LinearRegression(), random_state=42)\n",
    "ransac_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_ransac = ransac_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd09e4-d5d0-47b1-acef-00736fa92c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_models.append(y_pred_ransac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6963c8-561b-4d22-83ba-4e807bc1ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.append(ransac_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a514e-0de6-4158-a295-cd703d53789f",
   "metadata": {},
   "source": [
    "## 4.7 Theil-Sen Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f759a0-f0fa-46c7-9397-017e5d3dc0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theil-Sen Regression\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "theil_sen_regressor = TheilSenRegressor(random_state=42)\n",
    "theil_sen_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_theil_sen = theil_sen_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e23c5-46f5-47fb-af38-eb300278af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_models.append(y_pred_theil_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50e2d5-13bb-4fee-a5df-b6ac7226bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.append(theil_sen_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751c735-9acd-4e66-81f9-75ebffcc7a61",
   "metadata": {},
   "source": [
    "## 4.8 SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e218e29-5049-4e37-bec9-a39eac7fd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Regression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_regressor = SVR(kernel='rbf')\n",
    "svm_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_svm = svm_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92a797-17a1-44b9-a59a-486081132cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_models.append(y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190c254-1d34-4e10-b0e2-ca409677501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.append(svm_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f12507f-e243-4a38-abeb-4efdd62d667e",
   "metadata": {},
   "source": [
    "## 4.9 Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a6ef2-4ca2-4c1c-98a5-b1cede324eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest_regressor = RandomForestRegressor(random_state=42)\n",
    "random_forest_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_random_forest = random_forest_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d1901-3c63-47fb-9d2a-c9b50c0e1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_models.append(y_pred_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a0875-b4ce-478e-be83-22fc71cdb0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.append(random_forest_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831dc56-16de-4c88-8b2c-901834df6f5f",
   "metadata": {},
   "source": [
    "## 4.10 GBDT Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610012ad-4b65-4739-b457-815cd6027abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT Regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbdt_regressor = GradientBoostingRegressor(random_state=42)\n",
    "gbdt_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_gbdt = gbdt_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa9cb7-0934-4c37-b07e-18c9d20551d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_models.append(y_pred_gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ff736-d1c7-4350-b76b-f68e0a9ad60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.append(gbdt_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddfdae2-3694-49b5-a38d-f4bfc7171588",
   "metadata": {},
   "source": [
    "## 4.11 XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4551b452-61b6-468c-9197-e423b2d8deb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [2881.8096    987.0355    654.5816   1063.9218    799.1556    623.4902\n",
      "  544.87445   764.5704   1203.9313    443.52933   539.57324   517.59155\n",
      "  302.4451    538.87305  1070.6139    535.15515   392.54172   289.57382\n",
      " 1043.0571    878.81964   563.6099   1641.5386    726.9576    538.95374\n",
      "  214.83537   417.97888   316.17523   773.5574    555.8579   2427.901\n",
      "  395.18686   844.80524   303.89264  1142.4967   1804.6577    512.0645\n",
      "  532.33014   556.12555   130.11682   331.94202   924.26385   912.33905\n",
      "  950.4577    580.87384   950.7291    326.396     619.7407    533.15735\n",
      " 1911.1915    476.87476   886.6382    659.78125   542.1625    772.55304\n",
      "  353.57382   595.7083   1907.0536    640.7923   3921.557    1565.5074\n",
      "  296.07144  1024.124     762.53577   727.71936  1182.8412    163.15144\n",
      " 1265.2291    770.2396   1153.4967   1150.9954    479.65305  1090.0403\n",
      "  885.5009    421.00027  1739.7982   1173.4137    775.39667   187.15402\n",
      "  906.18256   618.586    1436.8627    373.7668    851.05817   634.6865\n",
      " 1312.8376    351.15768   671.37994  1691.1881   1901.1323    860.19763\n",
      "  656.4326    913.08234   601.4347    168.3826    382.68597   892.6826\n",
      " 1132.4781   1213.3148    929.4129    563.99207   834.2644    647.9839\n",
      "  426.68616  1012.99774   332.47232   198.15134  1244.1162   1763.3125\n",
      " 1666.536     802.1225   2752.0422   2190.5786    564.7881   1253.9668\n",
      "  617.01105   491.18115  1315.9327    765.10754  1054.1843    726.9576\n",
      " 1346.3586    663.71735   923.0453   1145.1376   1172.364    1588.2516\n",
      "  444.65192  1153.4967    524.61224   587.0207   2458.0098    444.5314\n",
      "  499.09592  1520.3804    489.8295   1081.6102    507.06064   661.16846\n",
      "  351.40625   883.08716  1047.8987    421.00027   507.01993  1741.384\n",
      "  379.3063    112.49136   261.6425   1181.6262   1320.2401   1045.3093\n",
      "  253.04921   396.79233   469.66986   593.0643    454.69955   289.07196\n",
      "  661.1121    763.07715  1931.8878   1272.7378    900.6814   1612.3481\n",
      " 1414.1476   1718.4346    440.9224   1512.2749    219.64322  1409.7747\n",
      "  411.89355   635.90674   960.6679    817.2815    889.0493    954.9023\n",
      "  721.94     1396.776     187.27548   797.6257   1140.5005    251.40358\n",
      " 1033.7738   1104.8273   1445.1686    745.99713   472.04977   221.48705\n",
      "  909.4525    534.5104    663.44037   526.0115   1480.5448   1063.9218\n",
      " 1120.1179    982.77167   252.45224   316.1565    726.9576     80.85427\n",
      "  733.46747  2881.8096    846.9837    833.63617   950.3613    753.50464\n",
      "  252.05264   727.71936  1115.6205   1205.488     282.2828    175.92772\n",
      " 4672.7593    567.8666   1620.4879    429.08423  1145.2216   1317.9958\n",
      " 1055.1135    500.49527  2112.9927   1031.7628   1217.0493    232.47305\n",
      " 1107.8408     23.346521  648.8367    726.9576   1032.8293    411.79034\n",
      " 2245.1387    351.20538   632.5761    271.20093   331.68777   300.66098\n",
      "  892.6826    302.4451   1934.7543    421.00027   444.5314    607.7557\n",
      " 1329.9965    983.98114  1065.3866    444.5314    726.9576    920.04926\n",
      "  295.61642   810.1514    873.2324     64.73537   444.5314   1769.374\n",
      "  305.46744   583.338    2426.51      181.59895   150.17036   913.9226\n",
      "  378.61786   731.54736   931.5188    728.3631    341.89658   691.5638\n",
      "  757.91986   675.71826   683.5562    997.88416   955.0714   1081.5555\n",
      " 1021.08887   467.23526   883.95715  1342.4518   1395.7628    437.10513\n",
      " 1619.2158    444.5314    482.70285   675.71826   933.277     392.2907\n",
      " 1169.772     489.8295    530.77747   645.1943    663.05206  1234.1941\n",
      " 1383.1045    944.30237  1407.4845    799.1556    168.35283  1287.3986\n",
      " 1327.7985    392.54172  1261.4886   1058.3396    489.8295    671.38666\n",
      " 1024.124     444.5314    290.8003    895.9819    364.68314   144.34932\n",
      "  424.0823    655.3909   1417.9646    987.51575   435.91492   651.7618\n",
      "  495.90744  1131.8223    614.7784    524.61224   592.09644   693.37006\n",
      "  527.1072    892.6826   1019.4162   2305.527     201.24898   862.1092\n",
      "  298.16364   432.6494   1810.7004    753.50464   905.3506     70.95958\n",
      "  986.74713   531.76697   391.15723   885.4573   2985.9902   1328.5348\n",
      "  553.6494   1096.6188   1777.7533    684.0698    724.4973    228.14978\n",
      "  618.34283   710.7793    486.2989    498.72342   302.4451   1063.9218\n",
      " 1407.9254    753.50464   590.47485  2057.0815    836.19635   423.56372\n",
      " 1119.5453    355.89874  1880.4283   1285.0043    460.61273  1094.8475\n",
      "  455.36218   323.15662   992.89154   967.14386  1830.5815    821.7667\n",
      "  811.4383    960.64777   874.49817   315.5596    937.40533   416.4287\n",
      " 1118.2223    692.1181    600.782    1973.081    1231.4796    557.5032\n",
      "   66.51706   421.00027  1345.3215    660.12036   485.93005  1083.4476\n",
      "  653.48615  1256.1888    742.45105   306.26367   303.59616  1107.8408\n",
      "   39.92284   436.5413    367.99164   626.2296    316.84448   804.33466\n",
      "  195.67828   513.07166   723.0363    990.0628   1445.1686    652.2158\n",
      "  268.3828    600.4306   1550.447     366.25235   288.77435  1249.8186\n",
      " 1809.0524    624.94745   552.1609    489.8295    652.73694   570.47394\n",
      "  428.62738  1359.7836   1140.5005    177.87036   357.51703   556.8522\n",
      "  565.10406   983.20166  1034.583    1290.4772    444.5314    391.10995\n",
      " 1182.6483    714.32355   645.1943   1040.9513    491.18115  1682.6621\n",
      "  910.81647  1163.9032    345.88635  1228.6288    489.8295    549.169\n",
      "  598.08936  1074.8333    660.5359   1163.4744    891.4934    261.36496\n",
      "  484.20648   472.15512   985.4103    833.63617   987.0355    660.1151\n",
      "  497.71436  1372.0093    665.69824   849.42346   383.44888  1047.8987\n",
      "  533.5577    771.9583    898.7354    458.92667  1081.5555   1063.9218\n",
      "  765.6648   1189.6543    342.90414  1062.1411    305.45377   519.76\n",
      "  450.48566   514.9419   3112.9807    588.04065   368.57434   621.16516\n",
      "  957.73254   755.96436  1205.8237   1503.939    1101.575     363.29132\n",
      "  420.8358    249.49724  1006.8179    520.44763   483.2314    782.5263\n",
      "  960.87915   349.1088    806.7162   1365.3556   1545.9027    470.14517\n",
      "  234.18625   444.5314    544.87445   482.42032   666.3085    674.58264\n",
      "  598.8315   2665.202     439.47205  2471.663     808.33826  1227.1617\n",
      " 1055.1135    892.6826   2263.845     851.0764    417.97888   775.6479\n",
      "  256.26782   314.02094   753.50464    39.92284   726.9576    915.3417\n",
      " 2307.053     516.05707   740.62354   470.33264   442.53253   657.6282\n",
      " 1045.8812   2549.1577   1457.6743   1653.8896    126.61531   894.89874\n",
      "  910.62787  1205.24      451.52893   424.77576  1444.0198    487.0284\n",
      " 1021.08887   228.36531  1226.4277    935.1075    600.312    2301.5103\n",
      "  155.63408   678.9489     71.03135  1800.6227    898.7354   1049.0583\n",
      "  147.96791   975.6687    633.31445  2394.2031   2264.9158    670.73\n",
      "  421.00027  2412.1777     51.517273  439.47205   477.49844  1107.5668\n",
      " 1089.5062   1031.0978    674.3573    427.01263   571.9335   2591.7717\n",
      "  207.1449    467.27383  1158.8824    333.9677    445.20065  2911.665\n",
      "  491.18115    95.047424 1675.3134    641.39056   650.1725   1153.4967\n",
      " 1937.3563    773.263     568.9724   1182.745     357.51703  1486.9316\n",
      "  645.58765   220.69214  1261.3932   1367.4822    440.92117   731.4839\n",
      "  916.2713    632.63763   878.1533    117.300964  530.8152   1087.2561\n",
      "  485.93005   731.4839    628.0309   1841.4833    713.27844   650.47095\n",
      " 2881.8096    346.28265  1394.2451    258.45883   965.67645   706.2152\n",
      "  641.1002    844.5651    483.46365  2427.0427   1017.39777  1441.7803\n",
      "  850.7885    741.0948   1017.78986  1037.6727   1300.6      2770.603\n",
      "  976.10016  1081.5555    726.9576    644.21106  1510.8662   2139.5493\n",
      " 2159.9219    514.95526  1067.7247    900.49255   298.62067   647.76715\n",
      "  172.652    1090.3146    389.86218   714.7875    439.47205  1016.75916\n",
      "  726.9576    644.21106   250.02834   780.27747   216.82925   804.68164\n",
      " 1586.8485    797.6257    441.46997   987.66003   428.19803   172.37645\n",
      "  417.23163   439.47205   125.08985   418.09335  1602.0067   1238.5685\n",
      "  330.24454  1376.5714   1213.4717    467.23526   652.0328    302.4451\n",
      "  491.0547    725.96014  1611.6794    847.8072    286.29276   848.1637\n",
      "  125.08985   527.68146   491.90598   789.2594    843.3377    551.2916\n",
      "  738.644     567.7244    738.85236   535.921     327.7823    173.68892\n",
      "  841.54315  1067.4695    921.3414    950.3613   1210.4049    489.8295\n",
      "  664.67114   876.1967   1194.9459    913.6136   1067.7247    910.62787\n",
      " 1611.6794    367.68558   835.23193  1028.9315    934.25     1300.792\n",
      " 1214.7208   2587.8455    401.4368    967.3815    444.5314    223.63927\n",
      "  307.02594  1434.8375    302.28595  1246.3519    584.75903   569.6272\n",
      "  804.54865   349.65326   263.68738  1126.3241    481.99994   191.56389\n",
      " 2782.7441    639.66095  1174.0408   1467.6483    237.51033   439.47205\n",
      " 2425.8145    237.11978   195.22025  2853.159     656.01013   546.9901\n",
      "  454.69955   872.7216   1078.5476    439.47205  1245.098     832.0568\n",
      "  623.62573   915.0854    685.4936    426.7576    499.5139    898.7354\n",
      " 2291.9976   1303.1467    506.29767   799.0545    377.1678    299.31454\n",
      " 1019.6124    377.1678    661.1121    194.8446    573.347     357.51703\n",
      " 1732.2549   1885.9111    517.3348   1045.2579    807.77844  2764.872\n",
      "  290.3424    760.174     593.0698    544.87445   377.1678   1082.4597\n",
      "  141.05399  1044.5474   1340.494    1858.1073    164.79942   230.6701\n",
      "  966.52454   327.9671    929.48444   710.0557    686.87683   448.27716\n",
      " 2096.2063  ]\n",
      "Actual values: [4149.99  719.99  479.88 1115.88  767.88  704.16  453.49  562.   1049.\n",
      "  298.85  369.99  548.    329.99  382.61 1089.    499.    399.99  219.\n",
      "  899.    999.    569.99  746.99  743.88  467.88  199.99  459.83  469.98\n",
      "  829.99  679.   2599.99  399.99  749.99  318.98 1439.99 2099.    689.99\n",
      "  537.48  599.99  160.07  299.    677.88 1028.35  969.41  699.99  949.99\n",
      "  209.99  189.99  399.   1399.99  469.    585.99  520.71  439.99  809.99\n",
      "  347.88  569.99 2799.99  587.88 2589.99 1772.95  229.9  1089.99  699.99\n",
      "  679.99 1249.99  199.   1449.99  799.   1128.    599.95  449.99 1169.99\n",
      " 1399.99  409.99 1489.99  538.99 1399.99  212.75  845.98  671.88 1599.\n",
      "  349.99 1019.88  589.99 1377.99  402.    595.   1919.88 2499.99 1149.99\n",
      "  698.99  749.99  644.95  149.99  599.99  928.   1309.99 1064.99  599.99\n",
      "  399.93  579.99  589.    548.   1049.    286.95  110.99 1199.    959.99\n",
      " 1409.99  791.88 2499.99  947.49  459.   1899.99  639.    527.88  999.99\n",
      "  719.88  969.99  743.88  799.99  209.6   779.   1299.   1149.65  925.\n",
      "  338.69 1128.    575.88  565.    899.    455.88  575.88 1299.99  443.88\n",
      " 1051.99  508.97  635.88  228.99  969.99  899.    409.99  539.88 1349.99\n",
      "  299.99  234.41  320.    969.03 1359.99  719.99  149.99  259.99  567.98\n",
      "  454.    439.24  287.    499.99  310.   1499.99  979.95  818.   1149.\n",
      "  749.99 1378.    258.   2399.99  269.99 1472.5   289.99  839.88 2389.99\n",
      " 1059.99 1079.88  719.31  649.99 1662.99  319.    799.99 1139.99  322.88\n",
      "  789.94 1159.99 1349.99  629.    287.88  284.99  799.99  499.    679.99\n",
      "  419.   1629.99 1115.88 1349.99 1519.99  150.69  172.98  743.88   60.\n",
      "  683.9  1739.99  640.99  969.    969.41  549.99  249.99  519.   1509.99\n",
      " 1299.    299.    202.79 5496.    586.96 2649.99  599.   1139.99 1599.99\n",
      " 1079.88  399.   1799.99 1269.99 1049.99  229.   1089.     63.99  749.\n",
      "  743.88 1237.49  285.99 2799.    999.    744.98  149.99  309.    219.69\n",
      "  928.    359.99 1599.9   409.99  455.88  487.   2279.88 2399.88  579.99\n",
      "  455.88  743.88  799.    217.69 1799.    283.99   59.55  455.88 2609.99\n",
      "  279.99  347.99 1599.99   89.    208.5   359.99  335.99  499.99  899.\n",
      "  459.99  219.    559.    581.95  511.15  199.9   899.   1199.99 1099.99\n",
      " 1029.    443.88 1319.99  599.99 2059.99  683.   1239.95  455.88  799.99\n",
      "  552.65  943.59  383.88  999.99  443.88  349.24  689.99  674.39 1522.68\n",
      " 1609.    929.   4999.99  767.88  184.99 1199.   1399.99  399.99 1249.\n",
      "  499.    443.88  590.28 1089.99  455.88  215.    835.    400.99   51.9\n",
      "  499.99  399.   1389.    871.19  383.88  399.99  199.   1799.99  789.\n",
      "  575.88  498.8   451.87  599.88  928.    859.   2199.99  204.    898.85\n",
      "  390.    529.99 2199.99  549.99 1709.     59.99  846.98  232.    265.\n",
      "  685.99 2199.99 1999.99  335.    276.88 1439.99  399.    695.88  229.98\n",
      "  461.66  849.99  599.    499.99  359.99 1115.88 1249.99  549.99  224.99\n",
      " 1297.    720.    407.15 1739.99  150.    129.99 1049.99  371.88  584.99\n",
      "  419.88  479.98  849.    899.99 1949.99  869.    399.99 1019.99  700.99\n",
      "  438.99  890.99  495.92 1039.99  623.88  639.   2428.99 1549.99  443.88\n",
      "   58.95  409.99 1219.99  319.99  399.99 1179.99  519.99 1511.88  503.8\n",
      "  407.88  269.99 1089.     93.98  359.99  149.   1055.88  296.99  799.99\n",
      "  359.99  349.99  749.    498.   1394.99  799.    679.99  439.93 2499.99\n",
      "  289.99  413.   1499.88 1426.99  498.88  289.    443.88  699.99  449.85\n",
      "  329.99 2199.   1139.99  161.99  359.88  799.99  549.99  949.99  719.\n",
      " 1599.99  455.88  274.99 1099.    695.88  689.99 1329.99  527.88 1659.99\n",
      "  814.99 1199.    239.99 1457.    443.88  583.99  559.99  999.98  539.\n",
      "  999.99 1499.99  269.99  443.88  729.99  699.    969.    859.99  670.72\n",
      "  408.98 1259.99  698.28  639.    199.99  899.    455.88  799.99  899.99\n",
      "  449.99 1099.99 1115.88 1299.99  799.99  239.   1429.    279.98  269.\n",
      "  439.24  390.99 3799.99  699.    383.88  379.99 1259.88  599.99  549.99\n",
      " 1399.99 1399.99  365.99  548.99  349.    679.    589.    519.    499.99\n",
      " 1999.    399.    799.99 1171.   1299.99  498.99  295.    455.88  419.88\n",
      "  343.99  903.6   839.99  399.   2799.99  479.97 2399.99 1319.    895.\n",
      " 1079.88  928.   2581.05  820.    459.83  741.51  282.    227.88  549.99\n",
      "   98.99  743.88 2159.88 2510.99  339.99  620.    375.99  549.    189.99\n",
      " 1399.99 2609.99 1618.8  2199.99  169.99 1139.88  879.99  639.    399.\n",
      "  462.   1399.99  399.99 1029.    209.    999.99  745.    629.99 2199.\n",
      "  159.    560.     99.99 1699.99  899.99 1099.99  169.5   529.99  718.8\n",
      " 3049.99 2399.99  799.99  409.99 1899.99   74.    323.98  579.99 1099.99\n",
      " 1659.   1759.    683.69  699.    349.    520.    146.74  440.   1999.99\n",
      "  359.    699.99 3290.99  527.88   65.99 1439.99  539.88  610.68 1128.\n",
      " 2299.99  449.99  579.   1139.    359.88 1499.    449.    149.    949.99\n",
      " 3699.    789.77  799.99  964.99  399.99  799.99  131.88  515.88  899.\n",
      "  753.99  799.99  819.   1599.99  799.99  827.88 3149.99  219.99 1223.99\n",
      "  219.   1129.96  649.99  549.99  799.99  269.99 2078.99 1285.   1059.\n",
      "  779.88  579.   1128.    919.99 1559.   2799.99  449.99 1099.99  743.88\n",
      "  659.88 1580.   3395.88 2599.99  599.88 1127.88 1799.99  489.97  585.99\n",
      "  666.99 1649.99  469.    349.99  479.97 1096.98  743.88  659.88  263.99\n",
      " 1099.99  679.99  599.99 1499.99  799.99  398.   1249.99  899.99  239.\n",
      "  254.99  323.98   59.99  409.99 1599.99  829.    539.9  1749.99 1409.\n",
      "  443.88  549.    329.99  199.9   677.   1889.99  549.99  309.99  649.8\n",
      "   63.98  658.79  649.99  797.74  995.88  749.99  649.99  459.99  809.99\n",
      "  639.    239.    239.88  635.9   599.99  839.99  969.41  619.99  443.88\n",
      "  560.    959.99  880.    699.   1127.88  929.99 1499.99  329.99 1019.99\n",
      "  977.99 1099.99 1299.99 1999.99 2099.    395.99  739.99  455.88  289.98\n",
      "  339.68 1229.99  219.99 1489.99  599.99  679.49  839.    335.    219.\n",
      " 1099.    439.99  169.99 2799.99  639.99 1299.99 1399.99  139.    479.97\n",
      " 2299.    316.    169.99 3666.99  799.    567.98  439.24  685.    959.88\n",
      "  323.98  776.99  949.99  249.99 1099.99  989.99  499.    489.99  899.99\n",
      " 1899.   1499.99  683.88  569.99  335.88  199.   1399.99  335.88  499.99\n",
      "  154.58  429.99  359.88 1772.95 1149.99  601.6  1099.99  719.99 2699.99\n",
      "  197.99  825.    623.88  419.88  335.88  999.    166.48 1029.   1349.99\n",
      " 1999.99  279.    369.99  359.99  483.   1349.99  649.99 1599.99  587.88\n",
      " 1649.  ]\n",
      "Root Mean Squared Error: 345.15837099658603\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Regression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_regressor = XGBRegressor(random_state=42)\n",
    "\n",
    "\n",
    "# Full pipeline with preprocessing and model\n",
    "XGBoost_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb_regressor)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "XGBoost_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "XGBoost_y_pred = XGBoost_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "XGBmse = mean_squared_error(y_test, XGBoost_y_pred)\n",
    "XGBrmse = np.sqrt(XGBmse)\n",
    "\n",
    "print(\"Predicted values:\", XGBoost_y_pred)\n",
    "print(\"Actual values:\", y_test.values)\n",
    "print(\"Root Mean Squared Error:\", XGBrmse)\n",
    "\n",
    "# xgb_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# y_pred_xgb = xgb_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c56192-1fb8-4be0-a1d1-20ad72ff1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_models.append(y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f75676-6952-40d4-9579-31a096efeafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.append(xgb_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f44059-6a79-4bb5-80f9-93d44232ee37",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba54fb-152b-4241-9bab-82be15ab9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First evaluating with MSE in order to identify the best models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_values = []\n",
    "\n",
    "\n",
    "# for each model computing the MSE\n",
    "for y_pred in y_pred_reg_models:\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "mse_df = pd.DataFrame({'Model': reg_model,'MSE': mse_values})\n",
    "\n",
    "mse_df = mse_df.sort_values(by='MSE')\n",
    "\n",
    "mse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3a1c8-e0c3-454d-b165-535bbaa8bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to extract model name from the 'Model' column\n",
    "def extract_model_name(model):\n",
    "    \n",
    "    # Extracts the model name before the first '(' if present\n",
    "    return re.split(r'\\(', str(model))[0]\n",
    "\n",
    "mse_df['Model Name'] = mse_df['Model'].apply(extract_model_name)\n",
    "\n",
    "# Reorder the columns to have 'Model Name' as the first column\n",
    "mse_df = mse_df[['Model Name', 'Model', 'MSE']]\n",
    "\n",
    "mse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f62f8-cdba-42c0-b02a-e93aba4c6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='MSE', y='Model Name', data=mse_df, hue=\"Model Name\", palette='viridis')\n",
    "plt.title('Mean Squared Error for Regression Models')\n",
    "plt.xlabel('Mean Squared Error')\n",
    "plt.ylabel('Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad7b97-2059-4533-ad04-758a6ab54de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing R2 Scores and Adjusted R2 Scores to check how good the model is in reality\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "top_models_df = mse_df.head(3)\n",
    "\n",
    "r2_scores = []\n",
    "adj_r2_scores = []\n",
    "\n",
    "n = len(y_test)  \n",
    "\n",
    "for i, row in top_models_df.iterrows():\n",
    "\n",
    "    model_name = row['Model']\n",
    "    \n",
    "    # Get the index of the model based on its name\n",
    "    model_index = reg_model.index(model_name)  \n",
    "    y_pred = y_pred_models[model_index]  # Retrieve the predictions for the model\n",
    "    \n",
    "    # Calculate RÂ² Score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    \n",
    "    # Calculate Adjusted RÂ² Score\n",
    "    p = X.shape[1]  # number of features\n",
    "    adj_r2 = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)\n",
    "    adj_r2_scores.append(adj_r2)\n",
    "\n",
    "\n",
    "top_reg_model = pd.DataFrame({\n",
    "    'Model_Name': top_models_df['Model'],\n",
    "    'MSE_Value': top_models_df['MSE'],\n",
    "    'R2_Score': r2_scores,\n",
    "    'adjR2_Score': adj_r2_scores\n",
    "})\n",
    "\n",
    "top_reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18c995-d1d3-402b-b8e2-48cd44fecebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_models = [] # TODO: Add the top 3 Models\n",
    "\n",
    "# Prepare figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot KDE for each model\n",
    "for i, model_name in enumerate(top_3_models):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    \n",
    "    # Get the actual and predicted values for each model\n",
    "    y_pred = y_pred_reg_models[i]  # Adjust index based on how you store the predictions\n",
    "    \n",
    "    # KDE plot of actual vs predicted values\n",
    "    sns.kdeplot(y_test, label='Actual', color='blue', fill=True)\n",
    "    sns.kdeplot(y_pred, label=f'Predicted by {model_name}', color='orange', fill=True)\n",
    "    \n",
    "    # Plot settings\n",
    "    plt.title(f'Actual vs Predicted Distribution: {model_name}', fontsize=14)\n",
    "    plt.xlabel('Area Worst')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8394da3-3ba4-4ccb-aae7-bb196d9a4bde",
   "metadata": {},
   "source": [
    "# 6. Hyperparameter Tuning Top 3 Performing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ac5b2-e8df-4197-aafa-52640846193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Skeleton Code to be Added post Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089bc334-e9f1-4412-b636-02f8ac2960cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da4f8cf-0d39-4456-b6e3-40a99d0ec5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901e950-0ab3-4b24-8056-b60206ead1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c385cb-29d7-431e-8cbf-82c9efd8a152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e525a482-a662-4842-8877-9f13b49a622c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7086538d-1a9c-486c-ad38-73839d39202a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b3b61-4aff-47d6-81d0-10290f7b9aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfcff00-d381-4af2-b0e2-721856f8e6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f31ec8-56d4-4e50-b1c9-04c3dd510cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c470f4-c67c-4246-8d9d-2326ecae94b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "239331bb-f30c-446c-a673-4773b8b66aaa",
   "metadata": {},
   "source": [
    "# 7. (Optional) Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ae485-55e5-4eea-8ffe-505f047b7663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b3366-8c36-4491-b701-2462b4114d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f684f-d683-4220-8d7a-4c949f517230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde5dca-eb2b-42fd-988d-01cfb4237181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9383c-1dc2-47e3-b4ff-b00acf7394d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ee417-cfd5-4bff-86e9-1b370dadc34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7699de-41b4-4b63-87a0-10a2d5f43bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f808bec-1e47-4f48-bdb5-5188f6c2b246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20392bd3-18a2-4bd5-934f-09e30528e671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64244871-918d-4499-96cf-e2d10c621b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0642fd-8220-4191-87a9-71fbcb2ea049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df220be7-60b3-4e8a-be8e-980fd8b6e298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03eb19-07b8-48d1-a290-d410e65f7ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe2e9c7-8798-40fe-bc28-ec3173a2512f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d589b-97fb-4a77-b179-a9fd569bf395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4543c-68c0-4a45-8faf-19ae6b9836ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3518d51-e2a4-4612-bda8-6fcc1aaf5c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea64bc-ebe2-4786-9cc7-3a93bf015449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a01caa-3399-4796-be17-c6282b4b2650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9895f-2493-4787-ba0d-4f57153726b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35217d-4246-4716-8ab4-d671fd251931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10291275-2d2b-4aaf-8409-89f355c5166b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a06265-de15-41a9-a1ca-03e975403f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d45ec-7f2d-4cc9-a9c2-bba1ae04f24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
